{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Bag-of-words\" data-toc-modified-id=\"Bag-of-words-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Bag of words</a></span></li><li><span><a href=\"#TF---IDF-(Term-Frequency---Inverse-Document-Frequency)\" data-toc-modified-id=\"TF---IDF-(Term-Frequency---Inverse-Document-Frequency)-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>TF - IDF (Term Frequency - Inverse Document Frequency)</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also known as count vectorisation (because it counts the unqiue words and represents it as a number).<br/>\n",
    "Note: Remember to remve stopwords from the documents, as they don't add any value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T15:37:23.161869Z",
     "start_time": "2021-03-30T15:37:09.338252Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras\n",
      "  Downloading Keras-2.4.3-py2.py3-none-any.whl (36 kB)\n",
      "Requirement already satisfied: h5py in c:\\users\\goutham-rog\\anaconda3\\lib\\site-packages (from keras) (2.10.0)\n",
      "Requirement already satisfied: numpy>=1.9.1 in c:\\users\\goutham-rog\\anaconda3\\lib\\site-packages (from keras) (1.18.5)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\goutham-rog\\anaconda3\\lib\\site-packages (from keras) (5.3.1)\n",
      "Requirement already satisfied: scipy>=0.14 in c:\\users\\goutham-rog\\anaconda3\\lib\\site-packages (from keras) (1.5.0)\n",
      "Requirement already satisfied: six in c:\\users\\goutham-rog\\anaconda3\\lib\\site-packages (from h5py->keras) (1.15.0)\n",
      "Installing collected packages: keras\n",
      "Successfully installed keras-2.4.3\n"
     ]
    }
   ],
   "source": [
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T14:22:00.746158Z",
     "start_time": "2021-03-31T14:21:54.768161Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary:['dog', 'a', 'live', 'in', 'home', 'hut', 'the', 'is']\n",
      "[[0. 1. 1. 1. 1. 1. 0. 0. 0.]\n",
      " [0. 1. 1. 1. 1. 0. 1. 1. 0.]\n",
      " [0. 1. 0. 0. 0. 1. 1. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "docs = [\n",
    "        'a dog live in home',\n",
    "        'a dog live in the hut',\n",
    "        'hut is dog home',\n",
    "]\n",
    "\n",
    "t = Tokenizer()\n",
    "t.fit_on_texts(docs)\n",
    "\n",
    "print(f'Vocabulary:{list(t.word_index.keys())}')\n",
    "\n",
    "vector = t.texts_to_matrix(docs, mode='count')\n",
    "print(vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drawbacks : \n",
    "This model is only concerned with whether known words occur in the document, not their position."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF - IDF (Term Frequency - Inverse Document Frequency)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF-IDF provides a way to give rarer words greater weight."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Term Freq: tf(t,d) <br/>\n",
    "This summarizes how often a gn word appears within a doc.\n",
    "Two methods are\n",
    "1. Term freq adjusted for document length: <br/>tf(t,d) = (number of times term t appear in document d ) / (number 0f words in d )\n",
    "2. logarithmically scaled freq: <br/> tf(t,d) = log ( 1 + number of times term t appear in document d )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "doc1 = 'a dog live in home'\n",
    "\n",
    "1. tf(dog,doc1) = 1/5\n",
    "2. tf(dog, doc1) = 1+ log(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T14:22:41.350165Z",
     "start_time": "2021-03-31T14:22:41.334165Z"
    }
   },
   "source": [
    "Inverse Document Freq: idf <br/>\n",
    "IDF measure of term importance. It is logarithmically scaled ratio of the total number of documents vs the count of documents with term t.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d = [\n",
    "        'a dog live in home',\n",
    "        'a dog live in the hut',\n",
    "        'hut is dog home',\n",
    "]\n",
    "D is the corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "idf(dog, D) = log(total no. of documents(3)/ total no. of documents with term 'dog')\n",
    "\n",
    "= log(3/3) = log(1) = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T14:30:31.269534Z",
     "start_time": "2021-03-31T14:30:31.239541Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabualry: ['dog', 'live', 'in', 'home', 'the', 'hut', 'is'] \n",
      "\n",
      "N\n",
      ":  [1.         1.28768207 1.28768207 1.28768207 1.69314718 1.28768207\n",
      " 1.69314718] \n",
      "\n",
      "idf = log(N/n):  {'dog': 0, 'live': 5, 'in': 3, 'home': 1, 'the': 6, 'hut': 2, 'is': 4} \n",
      "\n",
      "[[0.40912286 0.52682017 0.         0.52682017 0.         0.52682017\n",
      "  0.        ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "docs = [\n",
    "        'a dog live in home',\n",
    "        'a dog live in the hut',\n",
    "        'hut is dog home',\n",
    "]\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer.fit(docs)\n",
    "print('Vocabualry:', list(vectorizer.vocabulary_.keys()), '\\n')\n",
    "print('N\\n: ', vectorizer.idf_,'\\n')\n",
    "print('idf = log(N/n): ',vectorizer.vocabulary_,'\\n')\n",
    "vector = vectorizer.transform([docs[0]])\n",
    "print(vector.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drawbacks: <br/>\n",
    "    TF-IDF makes the feature extraction more robust than just counting the number of instances of a term in a document as presented in Bag-of-words model. But it doesnâ€™t solve for the major drawbacks of BoW model, the order or structure of words in the document is still discarded in TF-IDF model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
